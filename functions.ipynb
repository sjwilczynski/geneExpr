{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import itertools\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "import rpy2.robjects as robjects\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "\n",
    "class_names = np.array([\"No event\", \"Met event\"])\n",
    "\n",
    "\n",
    "def load_file(name):\n",
    "    return np.genfromtxt(name, delimiter=\",\", skip_header=1)\n",
    "\n",
    "\n",
    "def load_train_and_test_parts():\n",
    "    X_train = load_file(\"data/microarray_train.csv\")\n",
    "    X_test = load_file(\"data/microarray_test.csv\")\n",
    "    y_train = load_file(\"data/labels_train.csv\")\n",
    "    y_test = load_file(\"data/labels_test.csv\")\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(\n",
    "    axis, cm, classes, normalize=False, title=\"Confusion matrix\", cmap=cm.Blues\n",
    "):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    im = axis.imshow(cm, interpolation=\"nearest\", cmap=cmap, vmin=0, vmax=1)\n",
    "    axis.set(title=title, xlabel=\"Predicted label\", ylabel=\"True label\")\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    axis.set_xticks(tick_marks)\n",
    "    axis.set_xticklabels(classes)\n",
    "    axis.set_yticks(tick_marks)\n",
    "    axis.set_yticklabels(classes)\n",
    "\n",
    "    fmt = \".2f\" if normalize else \"d\"\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        axis.text(\n",
    "            j,\n",
    "            i,\n",
    "            format(cm[i, j], fmt),\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "        )\n",
    "\n",
    "    return im\n",
    "\n",
    "\n",
    "def plot_roc_curve(ax, clf, dataset, labels, title):\n",
    "\n",
    "    probs = clf.predict_proba(dataset)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(labels, probs)\n",
    "    roc_auc = roc_auc_score(labels, probs)\n",
    "\n",
    "    ax.plot(fpr, tpr, label=\"ROC curve (area = {:.2f})\".format(roc_auc))\n",
    "    ax.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "    ax.set(\n",
    "        xlabel=\"False Positive Rate\",\n",
    "        ylabel=\"True Positive Rate\",\n",
    "        title=title + \" ( Accuracy = {:.3f} )\".format(clf.score(dataset, labels)),\n",
    "    )\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "\n",
    "def fit_clf(clf, train_set, train_labels, test_set, test_labels, title):\n",
    "    clf = clf.fit(train_set, train_labels)\n",
    "    plot_clf_roc(clf, train_set, train_labels, test_set, test_labels, title)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def plot_clf_cm(clf, train_set, train_labels, test_set, test_labels):\n",
    "    test_labels_pred = clf.predict(test_set)\n",
    "    train_labels_pred = clf.predict(train_set)\n",
    "    test_cm = confusion_matrix(test_labels, test_labels_pred)\n",
    "    train_cm = confusion_matrix(train_labels, train_labels_pred)\n",
    "    fig, (ax1, ax2) = subplots(nrows=1, ncols=2, sharex=True, sharey=True)\n",
    "    im = plot_confusion_matrix(\n",
    "        ax1,\n",
    "        train_cm,\n",
    "        classes=class_names,\n",
    "        normalize=True,\n",
    "        title=\"Train confusion matrix\",\n",
    "    )\n",
    "    im = plot_confusion_matrix(\n",
    "        ax2, test_cm, classes=class_names, normalize=True, title=\"Test confusion matrix\"\n",
    "    )\n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "    fig.colorbar(im, cax=cbar_ax)\n",
    "    show()\n",
    "\n",
    "\n",
    "def plot_clf_roc(clf, train_set, train_labels, test_set, test_labels, title):\n",
    "    fig, (ax1, ax2) = subplots(\n",
    "        nrows=1, ncols=2, sharex=True, sharey=True, figsize=(12, 6)\n",
    "    )\n",
    "    fig.suptitle(title)\n",
    "    plot_roc_curve(ax1, clf, train_set, train_labels, title=\"Train\")\n",
    "    plot_roc_curve(ax2, clf, test_set, test_labels, title=\"Test\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def fit_models(train_set, train_labels, test_set, test_labels, plot_logit_weigths = False):\n",
    "    clf_logit = fit_clf(\n",
    "        LogisticRegression(solver=\"liblinear\", penalty=\"l1\", C=0.3),\n",
    "        train_set,\n",
    "        train_labels,\n",
    "        test_set,\n",
    "        test_labels,\n",
    "        \"Logistics regression\",\n",
    "    )\n",
    "    if plot_logit_weigths:\n",
    "        figure()\n",
    "        title('Logistics regression coefficients')\n",
    "        plot(np.arange(clf_logit.coef_.shape[1]), clf_logit.coef_[0])\n",
    "        show()\n",
    "    #clf_svm = fit_clf(SVC(gamma='scale', C=7, probability=True), train_set, train_labels, test_set, test_labels, 'SVM')\n",
    "    clf_forest = fit_clf(\n",
    "        RandomForestClassifier(max_depth=4, n_estimators=2000, min_samples_leaf=10),\n",
    "        train_set,\n",
    "        train_labels,\n",
    "        test_set,\n",
    "        test_labels,\n",
    "        \"Random forest\",\n",
    "    )\n",
    "    return (clf_logit, clf_forest)\n",
    "\n",
    "\n",
    "## MLCC\n",
    "def read_mlcc_result(filename, train_size):\n",
    "    robjects.r[\"load\"](\"./mlcc_results/{}\".format(filename))\n",
    "    s, m, b = robjects.r[\"res\"]\n",
    "    segmentation = np.asarray(s)\n",
    "    numb_clust = np.max(s)\n",
    "    mBIC = np.asarray(m)\n",
    "    b.names = robjects.r(\"0:{}\".format(numb_clust - 1))\n",
    "    bases = dict(zip(b.names, map(list, list(b))))\n",
    "    dimensionalities = np.empty(numb_clust, dtype=np.int32)\n",
    "    for i in range(numb_clust):\n",
    "        dimensionalities[i] = len(bases[str(i)]) // train_size\n",
    "    return segmentation - 1, mBIC, dimensionalities\n",
    "\n",
    "\n",
    "def apply_mlcc_dim_reduction(X, segmentation, dimensionalities):\n",
    "    numb_clust = dimensionalities.shape[0]\n",
    "    X_reduced = np.empty((X.shape[0], 0))\n",
    "    for i in range(numb_clust):\n",
    "        cluster = X[:, segmentation == i]\n",
    "        n_components = dimensionalities[i]\n",
    "        if cluster.shape[1] < n_components:  # TODO - maybe mlcc shouldn't allow it\n",
    "            print(\n",
    "                \"WARNING! Dimensionality of a cluster was greater than the number of variables. Ignoring this cluster.\"\n",
    "            )\n",
    "        else:\n",
    "            X_reduced = np.concatenate(\n",
    "                (X_reduced, PCA(n_components=n_components).fit_transform(cluster)),\n",
    "                axis=1,\n",
    "            )\n",
    "    return X_reduced\n",
    "\n",
    "\n",
    "def quantile_normalize(vec):\n",
    "    quants = np.quantile(vec, [0.25, 0.5, 0.75])\n",
    "    return (vec - quants[1]) / (quants[2] - quants[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomLogisticsRegressions:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_estimators=11,\n",
    "        penalty=\"l2\",\n",
    "        tol=1e-4,\n",
    "        C=1.0,\n",
    "        solver=\"liblinear\",\n",
    "        n_variables=1000,\n",
    "    ):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.estimators = [\n",
    "            LogisticRegression(penalty=penalty, tol=tol, C=C, solver=solver)\n",
    "            for x in np.arange(n_estimators)\n",
    "        ]\n",
    "        self.indices = []\n",
    "        self.n_variables = n_variables\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.indices = np.array(\n",
    "            [\n",
    "                np.random.choice(\n",
    "                    np.arange(X.shape[1]), size=self.n_variables, replace=False\n",
    "                )\n",
    "                for x in np.arange(self.n_estimators)\n",
    "            ]\n",
    "        )\n",
    "        for i in np.arange(self.n_estimators):\n",
    "            self.estimators[i].fit(X[:, self.indices[i, :]], y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        models_predictions = np.array(\n",
    "            [\n",
    "                model.predict(X[:, self.indices[i, :]])\n",
    "                for i, model in enumerate(self.estimators)\n",
    "            ]\n",
    "        )\n",
    "        mean_predictions = np.mean(models_predictions, axis=0)\n",
    "        return np.round(mean_predictions)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        models_probs = np.array(\n",
    "            [\n",
    "                model.predict_proba(X[:, self.indices[i, :]])\n",
    "                for i, model in enumerate(self.estimators)\n",
    "            ]\n",
    "        )\n",
    "        probabilities = np.mean(models_probs, axis=0)\n",
    "        return probabilities\n",
    "\n",
    "    def score(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        return accuracy_score(y, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
