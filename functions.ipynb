{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import itertools\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    auc,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "import rpy2.robjects as robjects\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import os\n",
    "\n",
    "\n",
    "class_names = np.array([\"No event\", \"Met event\"])\n",
    "\n",
    "\n",
    "def load_file(name):\n",
    "    return np.genfromtxt(name, delimiter=\",\", skip_header=1)\n",
    "\n",
    "\n",
    "def load_train_and_test_parts():\n",
    "    X_train = load_file(\"data/microarray_train.csv\")\n",
    "    X_test = load_file(\"data/microarray_test.csv\")\n",
    "    y_train = load_file(\"data/labels_train.csv\")\n",
    "    y_test = load_file(\"data/labels_test.csv\")\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(\n",
    "    axis, cm, classes, normalize=False, title=\"Confusion matrix\", cmap=cm.Blues\n",
    "):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    im = axis.imshow(cm, interpolation=\"nearest\", cmap=cmap, vmin=0, vmax=1)\n",
    "    axis.set(title=title, xlabel=\"Predicted label\", ylabel=\"True label\")\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    axis.set_xticks(tick_marks)\n",
    "    axis.set_xticklabels(classes)\n",
    "    axis.set_yticks(tick_marks)\n",
    "    axis.set_yticklabels(classes)\n",
    "\n",
    "    fmt = \".2f\" if normalize else \"d\"\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        axis.text(\n",
    "            j,\n",
    "            i,\n",
    "            format(cm[i, j], fmt),\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "        )\n",
    "\n",
    "    return im\n",
    "\n",
    "\n",
    "def plot_roc_curve(ax, clf, dataset, labels, title):\n",
    "\n",
    "    probs = clf.predict_proba(dataset)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(labels, probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    ax.plot(fpr, tpr, label=\"ROC curve (area = {:.2f})\".format(roc_auc))\n",
    "    ax.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "    ax.set(\n",
    "        xlabel=\"False Positive Rate\",\n",
    "        ylabel=\"True Positive Rate\",\n",
    "        title=title + \" ( Accuracy = {:.3f} )\".format(clf.score(dataset, labels)),\n",
    "    )\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "\n",
    "def fit_clf(clf, train_set, train_labels, test_set, test_labels, title):\n",
    "    clf = clf.fit(train_set, train_labels)\n",
    "    plot_clf_roc(clf, train_set, train_labels, test_set, test_labels, title)\n",
    "    # plot_clf_cm(clf, train_set, train_labels, test_set, test_labels)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def fit_clf_with_cross_val(clf, train_set, train_labels, test_set, test_labels, title):\n",
    "    fig, (ax1, ax2) = subplots(\n",
    "        nrows=1, ncols=2, sharex=True, sharey=True, figsize=(16, 8)\n",
    "    )\n",
    "    fig.suptitle(title)\n",
    "    fit_clf_cv(ax1, clf, train_set, train_labels, title=\"Train\")\n",
    "    plot_roc_curve(ax2, clf, test_set, test_labels, title=\"Test\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def fit_clf_cv(ax, clf, X, y, title):\n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    accs = [] \n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    i = 0\n",
    "    for train, test in cv.split(X, y):\n",
    "        model = clf.fit(X[train], y[train])\n",
    "        probas_ = model.predict_proba(X[test])\n",
    "        acc = model.score(X[test], y[test])\n",
    "        # Compute ROC curve and area the curve\n",
    "        fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs.append(roc_auc)\n",
    "        accs.append(acc)\n",
    "        ax.plot(\n",
    "            fpr, tpr, lw=1, alpha=0.3, label=\"ROC fold %d (AUC = %0.2f)\" % (i, roc_auc)\n",
    "        )\n",
    "\n",
    "        i += 1\n",
    "    ax.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    ax.plot(\n",
    "        mean_fpr,\n",
    "        mean_tpr,\n",
    "        color=\"b\",\n",
    "        label=r\"Mean ROC (AUC = %0.2f $\\pm$ %0.2f)\" % (mean_auc, std_auc),\n",
    "        lw=2,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(\n",
    "        mean_fpr,\n",
    "        tprs_lower,\n",
    "        tprs_upper,\n",
    "        color=\"grey\",\n",
    "        alpha=0.2,\n",
    "        label=r\"$\\pm$ 1 std. dev.\",\n",
    "    )\n",
    "\n",
    "    ax.set_xlim([-0.05, 1.05])\n",
    "    ax.set_ylim([-0.05, 1.05])\n",
    "    ax.set_xlabel(\"False Positive Rate\")\n",
    "    ax.set_ylabel(\"True Positive Rate\")\n",
    "    ax.set_title(title + r\" ( Accuracy = %0.2f $\\pm$ %0.2f )\" % (np.mean(accs), np.std(accs)))\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "\n",
    "def fit_clf_no_plot(clf, train_set, train_labels, test_set, test_labels):\n",
    "    clf = clf.fit(train_set, train_labels)\n",
    "    _, _, train_roc_score = calculate_roc_score(clf, train_set, train_labels)\n",
    "    _, _, test_roc_score = calculate_roc_score(clf, test_set, test_labels)\n",
    "    return clf, train_roc_score, test_roc_score\n",
    "\n",
    "\n",
    "def plot_clf_cm(clf, train_set, train_labels, test_set, test_labels):\n",
    "    test_labels_pred = clf.predict(test_set)\n",
    "    train_labels_pred = clf.predict(train_set)\n",
    "    test_cm = confusion_matrix(test_labels, test_labels_pred)\n",
    "    train_cm = confusion_matrix(train_labels, train_labels_pred)\n",
    "    fig, (ax1, ax2) = subplots(nrows=1, ncols=2, sharex=True, sharey=True)\n",
    "    im = plot_confusion_matrix(\n",
    "        ax1,\n",
    "        train_cm,\n",
    "        classes=class_names,\n",
    "        normalize=True,\n",
    "        title=\"Train confusion matrix\",\n",
    "    )\n",
    "    im = plot_confusion_matrix(\n",
    "        ax2, test_cm, classes=class_names, normalize=True, title=\"Test confusion matrix\"\n",
    "    )\n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "    fig.colorbar(im, cax=cbar_ax)\n",
    "    show()\n",
    "\n",
    "\n",
    "def plot_clf_roc(clf, train_set, train_labels, test_set, test_labels, title):\n",
    "    fig, (ax1, ax2) = subplots(\n",
    "        nrows=1, ncols=2, sharex=True, sharey=True, figsize=(12, 6)\n",
    "    )\n",
    "    fig.suptitle(title)\n",
    "    plot_roc_curve(ax1, clf, train_set, train_labels, title=\"Train\")\n",
    "    plot_roc_curve(ax2, clf, test_set, test_labels, title=\"Test\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def fit_models(\n",
    "    train_set, train_labels, test_set, test_labels, plot_logit_weigths=False\n",
    "):\n",
    "    clf_logit = fit_clf(\n",
    "        LogisticRegression(solver=\"liblinear\", penalty=\"l1\", C=0.3),\n",
    "        train_set,\n",
    "        train_labels,\n",
    "        test_set,\n",
    "        test_labels,\n",
    "        \"Logistics regression\",\n",
    "    )\n",
    "    if plot_logit_weigths:\n",
    "        plot_logit_weights(clf_logit, \"Logistics regression coefficients\")\n",
    "    # clf_svm = fit_clf(SVC(gamma='scale', C=7, probability=True), train_set, train_labels, test_set, test_labels, 'SVM')\n",
    "    clf_forest = fit_clf(\n",
    "        RandomForestClassifier(max_depth=4, n_estimators=2000, min_samples_leaf=10),\n",
    "        train_set,\n",
    "        train_labels,\n",
    "        test_set,\n",
    "        test_labels,\n",
    "        \"Random forest\",\n",
    "    )\n",
    "    return (clf_logit, clf_forest)\n",
    "\n",
    "\n",
    "def plot_logit_weights(clf_logit, title):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.plot(np.arange(clf_logit.coef_.shape[1]), clf_logit.coef_[0])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_logit_weights_ax(ax, clf_logit, title):\n",
    "    ax.set_title(title)\n",
    "    ax.plot(np.arange(clf_logit.coef_.shape[1]), clf_logit.coef_[0])\n",
    "\n",
    "\n",
    "## MLCC\n",
    "def read_mlcc_result(filename, train_size):\n",
    "    robjects.r[\"load\"](\"./mlcc_results/{}\".format(filename))\n",
    "    s, m, b = robjects.r[\"res\"]\n",
    "    segmentation = np.asarray(s)\n",
    "    numb_clust = np.max(s)\n",
    "    mBIC = np.asarray(m)\n",
    "    b.names = robjects.r(\"0:{}\".format(numb_clust - 1))\n",
    "    bases = dict(zip(b.names, map(list, list(b))))\n",
    "    dimensionalities = np.empty(numb_clust, dtype=np.int32)\n",
    "    for i in range(numb_clust):\n",
    "        dimensionalities[i] = len(bases[str(i)]) // train_size\n",
    "    return segmentation - 1, mBIC, dimensionalities\n",
    "\n",
    "\n",
    "def apply_mlcc_dim_reduction(X, segmentation, dimensionalities):\n",
    "    numb_clust = dimensionalities.shape[0]\n",
    "    X_reduced = np.empty((X.shape[0], 0))\n",
    "    for i in range(numb_clust):\n",
    "        cluster = X[:, segmentation == i]\n",
    "        n_components = dimensionalities[i]\n",
    "        if cluster.shape[1] < n_components:  # TODO - maybe mlcc shouldn't allow it\n",
    "            print(\n",
    "                \"WARNING! Dimensionality of a cluster was greater than the number of variables. Ignoring this cluster.\"\n",
    "            )\n",
    "        else:\n",
    "            X_reduced = np.concatenate(\n",
    "                (X_reduced, PCA(n_components=n_components).fit_transform(cluster)),\n",
    "                axis=1,\n",
    "            )\n",
    "    return X_reduced\n",
    "\n",
    "\n",
    "def quantile_normalize(vec):\n",
    "    quants = np.quantile(vec, [0.25, 0.5, 0.75])\n",
    "    return (vec - quants[1]) / (quants[2] - quants[0])\n",
    "\n",
    "\n",
    "def flatten(nested_list):\n",
    "    return [item for sublist in nested_list for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomLogisticsRegressions:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_estimators=11,\n",
    "        penalty=\"l2\",\n",
    "        tol=1e-4,\n",
    "        C=1.0,\n",
    "        solver=\"liblinear\",\n",
    "        n_variables=1000\n",
    "    ):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.estimators_ = [\n",
    "            LogisticRegression(penalty=penalty, tol=tol, C=C, solver=solver)\n",
    "            for x in np.arange(n_estimators)\n",
    "        ]\n",
    "        self.indices = []\n",
    "        self.n_variables = n_variables\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.indices = np.array(\n",
    "            [\n",
    "                np.random.choice(\n",
    "                    np.arange(X.shape[1]), size=self.n_variables, replace=False\n",
    "                )\n",
    "                for x in np.arange(self.n_estimators)\n",
    "            ]\n",
    "        )\n",
    "        for i in np.arange(self.n_estimators):\n",
    "            self.estimators_[i].fit(X[:, self.indices[i, :]], y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        models_predictions = np.array(\n",
    "            [\n",
    "                model.predict(X[:, self.indices[i, :]])\n",
    "                for i, model in enumerate(self.estimators_)\n",
    "            ]\n",
    "        )\n",
    "        mean_predictions = np.mean(models_predictions, axis=0)\n",
    "        return np.round(mean_predictions)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        models_probs = np.array(\n",
    "            [\n",
    "                model.predict_proba(X[:, self.indices[i, :]])\n",
    "                for i, model in enumerate(self.estimators_)\n",
    "            ]\n",
    "        )\n",
    "        probabilities = np.mean(models_probs, axis=0)\n",
    "        return probabilities\n",
    "\n",
    "    def score(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        return accuracy_score(y, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
