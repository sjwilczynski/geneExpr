{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%run functions.ipynb\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test sizes: (726, 12179) (243, 12179)\n",
      "(1, 0) labels count in train test: (289, 437) (104, 139)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_train_and_test_parts()\n",
    "print(\"Train and test sizes: {} {}\".format(X_train.shape, X_test.shape))\n",
    "print(\n",
    "    \"(1, 0) labels count in train test: {} {}\".format(\n",
    "        (np.count_nonzero(y_train == 1), np.count_nonzero(y_train == 0)),\n",
    "        (np.count_nonzero(y_test == 1), np.count_nonzero(y_test == 0)),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "scoring = 'roc_auc'\n",
    "cv = 4\n",
    "cv_out = 5\n",
    "cv_in = 2\n",
    "n_iter = 1\n",
    "n_jobs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_variables': 500, 'n_estimators': 250, 'C': 0.7000000000000001}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.974</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.825</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ROC AUC  Precision  Recall    F1\n",
       "train    0.974      0.961   0.855 0.905\n",
       "test     0.825      0.739   0.654 0.694"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rlr_params = {'C' : np.linspace(0.1, 5, 50), 'n_estimators' : [100, 250, 500, 1000], 'n_variables' : [100, 250, 500, 1000]}\n",
    "rlr_cv = RandomizedSearchCV(RandomLogisticsRegressions(penalty='l1'), cv=cv, scoring=scoring, n_iter=n_iter, n_jobs=n_jobs, \n",
    "                                iid=False, param_distributions=rlr_params, random_state=random_state)\n",
    "\n",
    "clf_rlr = fit_clf_print_scores(rlr_cv, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores_names = ['roc_auc', 'precision', 'recall', 'f1']\n",
    "estimated_scores = {}\n",
    "randomized_cvs = {}\n",
    "models = {\n",
    "    'Random logistic regression': {\n",
    "        'model': RandomLogisticsRegressions(penalty='l1'),\n",
    "        'params': {'C' : np.linspace(0.1, 5, 50), 'n_estimators' : [100, 250, 500, 1000], 'n_variables' : [100, 250, 500, 1000]}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model_specification in models.items():\n",
    "    rcv = RandomizedSearchCV(estimator=model_specification['model'], param_distributions=model_specification['params'],\n",
    "                             cv=cv_in, scoring=scoring, n_iter=n_iter, iid=False, random_state=random_state)\n",
    "    randomized_cvs[model_name] = rcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for Random logistic regression\n"
     ]
    }
   ],
   "source": [
    "for name, rcv in randomized_cvs.items():\n",
    "    nested_scores = cross_validate(rcv, X_train, y_train, scoring = all_scores_names, cv=cv_out)\n",
    "    estimated_scores[name] = {}\n",
    "    for score_name in all_scores_names:\n",
    "        estimated_scores[name][score_name] = {\n",
    "            'mean': np.mean(nested_scores['test_' + score_name]),\n",
    "            'std': np.std(nested_scores['test_' + score_name])\n",
    "        }\n",
    "    print('Done for ' + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random logistic regression</th>\n",
       "      <td>0.809 $\\pm$ 0.028</td>\n",
       "      <td>0.709 $\\pm$ 0.043</td>\n",
       "      <td>0.633 $\\pm$ 0.019</td>\n",
       "      <td>0.668 $\\pm$ 0.023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      ROC AUC          Precision             Recall                 F1\n",
       "Random logistic regression  0.809 $\\pm$ 0.028  0.709 $\\pm$ 0.043  0.633 $\\pm$ 0.019  0.668 $\\pm$ 0.023"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "{} &            ROC AUC &          Precision &             Recall &                 F1 \\\\\n",
      "\\midrule\n",
      "Random logistic regression &  0.809 \\$\\textbackslash pm\\$ 0.028 &  0.709 \\$\\textbackslash pm\\$ 0.043 &  0.633 \\$\\textbackslash pm\\$ 0.019 &  0.668 \\$\\textbackslash pm\\$ 0.023 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_summarized_scores(estimated_scores, models, latex=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
