{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import rpy2.robjects as robjects\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functions import *\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "np.random.seed(42)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try [fDNN](https://www.nature.com/articles/s41598-018-34833-6) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(969,) (969, 12179)\n",
      "Train and test sizes: (726, 12179) (243, 12179)\n",
      "(1, 0) labels count in train test: (289, 437) (104, 139)\n"
     ]
    }
   ],
   "source": [
    "labels = load_file('data/labels_for_microarray_data.csv')\n",
    "labels = np.array(labels, dtype=np.int32)\n",
    "dataset = load_file('data/microarray_data.csv')[:, 1:].T\n",
    "print(labels.shape, dataset.shape)\n",
    "X_train, X_test, y_train, y_test = load_train_and_test_parts()\n",
    "print(\"Train and test sizes: {} {}\".format(X_train.shape, X_test.shape))\n",
    "print(\"(1, 0) labels count in train test: {} {}\".format((np.count_nonzero(y_train==1), np.count_nonzero(y_train==0)), \n",
    "                                                        (np.count_nonzero(y_test==1), np.count_nonzero(y_test==0))))\n",
    "standarizer = StandardScaler().fit(X_train)\n",
    "X_std_train = standarizer.transform(X_train)\n",
    "X_std_test = standarizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test scores: 0.8732782369146006 0.691358024691358\n"
     ]
    }
   ],
   "source": [
    "clf_forest = fit_clf(RandomForestClassifier(max_depth=4, n_estimators=50, min_samples_leaf=10), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_representation(clf, data):\n",
    "    result = np.zeros((data.shape[0], len(clf.estimators_)), dtype=np.int32)\n",
    "    for i, tree in enumerate(clf.estimators_):\n",
    "        result[:, i] = tree.predict(data)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tree_train = tree_representation(clf_forest, X_train)\n",
    "X_tree_test = tree_representation(clf_forest, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_logit = fit_models(X_tree_train, y_train, X_tree_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpressionDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx, :]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample, self.labels[idx]\n",
    "    \n",
    "tree_train_dataset = ExpressionDataset(X_tree_train, y_train, lambda x : torch.from_numpy(x))\n",
    "tree_test_dataset = ExpressionDataset(X_tree_test, y_test, lambda x : torch.from_numpy(x))\n",
    "\n",
    "tree_train_loader = DataLoader(tree_train_dataset, batch_size=16)\n",
    "tree_test_loader = DataLoader(tree_test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "\n",
    "    def __init__(self, size):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(size[0], size[1])\n",
    "        self.fc2 = nn.Linear(size[1], size[2])\n",
    "        self.fc3 = nn.Linear(size[2], 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return torch.sigmoid(self.fc3(x)).view(-1)\n",
    "\n",
    "\n",
    "net = SimpleNet([tree_train_dataset[0][0].shape[0], 50, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 loss: 0.696\n",
      "Batch 2 loss: 0.674\n",
      "Batch 3 loss: 0.675\n",
      "Batch 4 loss: 0.653\n",
      "Batch 5 loss: 0.664\n",
      "Batch 6 loss: 0.557\n",
      "Batch 7 loss: 0.569\n",
      "Batch 8 loss: 0.668\n",
      "Batch 9 loss: 0.644\n",
      "Batch 10 loss: 0.401\n",
      "Batch 11 loss: 0.680\n",
      "Batch 12 loss: 0.680\n",
      "Batch 13 loss: 0.566\n",
      "Batch 14 loss: 0.618\n",
      "Batch 15 loss: 0.508\n",
      "Batch 16 loss: 0.565\n",
      "Batch 17 loss: 0.508\n",
      "Batch 18 loss: 0.469\n",
      "Batch 19 loss: 0.458\n",
      "Batch 20 loss: 0.442\n",
      "Batch 21 loss: 0.775\n",
      "Batch 22 loss: 0.516\n",
      "Batch 23 loss: 0.377\n",
      "Batch 24 loss: 0.306\n",
      "Batch 25 loss: 0.355\n",
      "Batch 26 loss: 0.521\n",
      "Batch 27 loss: 0.361\n",
      "Batch 28 loss: 0.377\n",
      "Batch 29 loss: 0.383\n",
      "Batch 30 loss: 0.478\n",
      "Batch 31 loss: 0.211\n",
      "Batch 32 loss: 0.300\n",
      "Batch 33 loss: 0.379\n",
      "Batch 34 loss: 0.239\n",
      "Batch 35 loss: 0.330\n",
      "Batch 36 loss: 0.188\n",
      "Batch 37 loss: 0.449\n",
      "Batch 38 loss: 0.239\n",
      "Batch 39 loss: 0.344\n",
      "Batch 40 loss: 0.130\n",
      "Batch 41 loss: 0.499\n",
      "Batch 42 loss: 0.222\n",
      "Batch 43 loss: 0.262\n",
      "Batch 44 loss: 0.463\n",
      "Batch 45 loss: 0.136\n",
      "Batch 46 loss: 0.653\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for i, (inputs, labels) in enumerate(tree_train_loader):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = net(inputs.float())\n",
    "    loss = criterion(outputs, labels.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "    print('Batch %d loss: %.3f' % (i + 1, running_loss))\n",
    "    running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 70 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in tree_test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images.float())\n",
    "        predicted = torch.round(outputs)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.float()).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 90 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in tree_train_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images.float())\n",
    "        predicted = torch.round(outputs)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.float()).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
